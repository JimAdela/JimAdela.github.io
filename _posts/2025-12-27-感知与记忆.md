---
layout:     post
title:      感知与记忆：CNN、RNN 与扩散模型的数学直觉
subtitle:   从局部滤镜到全局关联，再到无中生有的艺术
date:       2025-12-27
author:     WY
header-img: img/post-bg-cnn-rnn.jpg
catalog: true
tags:
    - CNN
    - RNN
    - 扩散模型
    - 计算机视觉
---

## 第二十章：CNN (卷积神经网络) —— 空间感受野

### 1. 卷积 (Convolution) 的本质：局部点积
*   **数学动作**：一个小矩阵（卷积核）在图像上滑动，每一步都与覆盖的局部像素做**点积**。
*   **物理意义**：它是“特征提取器”。有的核对边缘敏感，有的对色彩敏感。
*   **AI 优势**：**参数共享**。同一个“眼睛”看全图，大大减少了参数量，且能识别位置无关的特征。

### 2. 池化 (Pooling)：降维与平移不变性
*   **动作**：取局部区域的最大值（Max Pooling）。
*   **直觉**：只保留最强烈的特征，忽略微小的位置偏移。让 AI 在猫稍微移动一点时依然认得它是猫。

---

## 第二十一章：RNN (循环神经网络) —— 时间的刻度

### 1. 循环 (Recurrence) 公式
$$h_t = \text{tanh}(W x_t + U h_{t-1})$$
*   **$h_{t-1}$**：这就是“记忆”的数学表示。
*   **数学痛点**：由于链式法则是连乘，当序列很长时，梯度会呈指数级缩小（梯度消失）。
*   **现状**：在长文本处理上已被 Transformer 取代，但在实时性极高的短流数据（如实时心电图）中仍有应用。

---

## 第二十二章：扩散模型 (Diffusion) —— 概率逆转的艺术

### 1. 过程：加噪与去噪
*   **前向 (Forward)**：通过高斯变换将图片变成纯噪声（熵增过程）。
*   **后向 (Reverse)**：AI 学习的是**条件概率 $P(x_{t-1}|x_t)$**，即“如何从混乱中预测出上一时刻的秩序”。
*   **数学本质**：它不是在“画图”，而是在**高维概率空间中通过微调向量来寻找最符合描述的样本点**。

---